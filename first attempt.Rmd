---
title: "Movielens project"
author: "awala fortune o."
output:
  pdf_document: 
    fig_caption: yes
    keep_tex: yes
    toc: yes
  html_document:
    df_print: paged
smoth_scroll: no
collapse: no
toc: yes
toc_float: yes
---
###Introduction###
Recommender Systems has gained much popularity in data science community  because of the Netflix prize contest. It has emerged as an important factor for e-commerce and as  machine learning technology it has a wide range of application in most industries today.

The movielens project is aimed at creating recommendation system using the edx data set in the training of the algorithms and  movie ratings prediction.The Root Mean Square Error are used to evaluate the closeness of the predictions to the true values in the validation set. The 10M version of the MovieLens dataset were generated by the GroupLens research lab. 
###Method/Analysis###
The main methods of this paper targets to develop a recommender system based on users ratings and to evaluate the system using simple baseline techniques such as  Linear regression model with regularized movie and user effects using Lambda for validation. And further built models based on popularity, similarity between items and similarity between users hence, optimizing  Root Mean Square Error (RMSE)between the predicted and actual ratings as shown in the formula:
RMSE = function(m, o){
  sqrt(mean((m - o)^2))
}
where,   m: is for model (fitted) values and o: is for observed (true) values.

                                  
##Dataset##
```{r}
load("~/Awala Capstone Project/Awala_Fortune_Project.rda")
```

#Loading library and dataset#

```{r}
library(tidyverse)
```
```{r}
library(caret)
```
```{r}
library(data.table)
```
```{r}
library(kableExtra)
```
```{r}
library(lubridate)
```
```{r}
library(Matrix.utils)
```
```{r}
library(DT)
```
```{r}
library(wordcloud) 
```
```{r}
library(RColorBrewer)
```
```{r}
library(ggthemes) 
```
```{r}
library(irlba)
```
```{r}
library(recommenderlab)
```
```{r}
library(recosystem)
```
```{r}
library(h2o)
```
```{r}
library(googledrive)
```
```{r}
library(stringr)
```
```{r}
url <- "https://drive.google.com/drive/folders/1IZcBBX0OmL9wu9AdzMBFUG8GoPbGQ38D?usp=sharing"
```
```{r}
dl <- tempfile()
download.file(url, dl)
```
```{r}
validation <- readRDS("C:/Users/HP/Downloads/validation.rds")
edx <- readRDS("C:/Users/HP/Downloads/edx.rds")
```
###Results###
After generating codes provided in the project overview, it is observed that the edX dataset is made of 6 features for a total of about 9,000,055 observations.The validation set which represents 10% of the 10M Movielens dataset contains the same features , but with a total of 999,999 occurences. we made sure that userId and movieId in edx set are also in validation set.
Each row represents a rating given by one user to one movie. The column “rating” is the outcome we want to predict, y. Taking into account both dataset, edx dataset is used to predict while validation dataset is used for validation below. 
##Data Exploration##
```{r}
head(edx)
```
```{r}
class(edx)
```

```{r}
glimpse(edx)
```

```{r}
dim(edx)
```

```{r}
summary(edx)
```

```{r}
#create a dataframe "explore_edx_ratings" which contains half star and whole star ratings  from the edx dataset
group <-  ifelse((edx$rating == 1 |edx$rating == 2 | edx$rating == 3 | 
                  edx$rating == 4 | edx$rating == 5) ,
                   "whole_star", 
                   "half_star") 
```

```{r}
explore_edx_ratings <- data.frame(edx$rating, group)
```

```{r}
#Histogram
ggplot(explore_edx_ratings, aes(x= edx.rating, fill = group)) +
  geom_histogram( binwidth = 0.2) +
  scale_x_continuous(breaks=seq(0, 5, by= 0.5)) +
  scale_fill_manual(values = c("half_star"="blue", "whole_star"="red")) +
  labs(x="rating", y="number of ratings", caption = "source data: edx set") +
  ggtitle("histogram : number of ratings per rating")
```
Exploring ratings of the edx dataset, it is observed that the average user's activity reveals that no user gives 0 as rating, the top 5 ratings from most to least are :  4, 3, 5, 3.5 and 2. The histogram shows that the half star ratings are less common than whole star ratings.
```{r}
edx %>% group_by(rating) %>% summarize(count = n()) %>% top_n(5, count) %>%
	arrange(desc(count))
```

```{r}
edx %>%
	group_by(rating) %>%
	summarize(count = n()) %>%
	ggplot(aes(x = rating, y = count)) +
	geom_line()+
  labs(x="rating", y="number of ratings", caption = "source data: edx set") +
  ggtitle("geomplot : number of ratings per count")
```
The result above shows that the rating was rated highest at point 4 and 5.

Exploration of the features contained in “genres” and “title” of our edx dataset.
```{r}
#create a data frame top_genr which contains each single genre without their combinations ( ex : Action and not "Action|Crime|Thriller" , Comedy and not  "Comedy|Romance") . In this way i can visualize which single genre has more ratings
top_genr <- edx %>% separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

datatable(top_genr, rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) ) %>%
  formatRound('count',digits=0, interval = 3, mark = ",")
```


```{r}
# plot a word cloud
layout(matrix(c(1,2), nrow =2) , heights = c(1,4))
par(mar=rep(0,4))
plot.new()
text(x=0.5,y=0.5, "top Genres by number of ratings")
wordcloud(words=top_genr$genres,freq=top_genr$count,min.freq=50,
          max.words = 20,random.order=FALSE,random.color=FALSE,
          rot.per=0.35,colors = brewer.pal(8,"Dark2"),scale=c(5,.2),
          family="plain",font=2,
          main = "Top genres by number of ratings")
```


```{r}
 edx %>%
  group_by(title, genres) %>%
  summarize(count=n()) %>%
  top_n(5,count) %>%
  arrange(desc(count))
```


```{r}
# the data frame top_title contains the top 20 movies which count the major number of ratings
top_title <- edx %>%
  group_by(title) %>%
  summarize(count=n()) %>%
  top_n(20,count) %>%
  arrange(desc(count))

# with the head function i output the top 5 

kable(head(edx %>%
     group_by(title,genres) %>%
     summarize(count=n()) %>%
     top_n(20,count) %>%
     arrange(desc(count)) ,
     5)) %>%
  kable_styling(bootstrap_options = "bordered", full_width = F , position ="center") %>%
  column_spec(1,bold = T ) %>%
  column_spec(2,bold =T) %>%
  column_spec(3,bold=T)
```

```{r}
#bar chart of top_title
top_title %>% 
  ggplot(aes(x=reorder(title, count), y=count)) +
  geom_bar(stat='identity', fill="blue") + coord_flip(y=c(0, 40000)) +
  labs(x="", y="Number of ratings") +
  geom_text(aes(label= count), hjust=-0.1, size=3) +
  labs(title="Top 20 movies title based \n on number of ratings" , caption = "source data: edx set")
```
From the “title” attributes it is observed that it is in line with the previous analysis. The movies which have the highest number of ratings are in the top genres categories : movies like Pulp fiction (1994), Forrest Gump(1994) or Jurrasic Park(1993) which are in the top 5 of movie’s ratings number , are part of the Drama, Comedy or Action genres.

```{r}
edx %>%
group_by(movieId) %>%
summarize(count = n()) %>%
filter(count == 1) %>%
left_join(edx, by = "movieId") %>%
group_by(title) %>%
summarize(rating = rating, n_rating = count) %>%
slice(1:20) %>%
knitr::kable()
```

```{r}
genres_popularity <- edx %>%
  select(movieId, genres) %>% 
  mutate(genres = as.factor(genres)) %>% 
  group_by(movieId, genres) %>% 
  summarise(number = n()) %>% 
  complete(genres, fill = list(number = 20)) 

genres_popularity %>%
  filter(genres %in% c("War", "Sci-Fi", "Animation", "Western")) %>%
  ggplot(aes(x = genres, y = number)) +
  geom_line(aes(color=genres)) +
  scale_fill_brewer(palette = "Paired") 
```


```{r}
#An error bar plots for genres with more than 100000 ratings
edx %>% group_by(genres) %>%
  summarize(n = n(), avg = mean(rating), se = sd(rating)/sqrt(n())) %>%
  filter(n >= 100000) %>% 
  mutate(genres = reorder(genres, avg)) %>%
  ggplot(aes(x = genres, y = avg, ymin = avg - 2*se, ymax = avg + 2*se)) + 
  geom_point() +
  geom_errorbar() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "error bar plots by genres" , caption = "source data : edx set") +
  theme(
    panel.background = element_rect(fill = "lightblue",
                                    colour = "lightblue",
                                    size = 0.5, linetype = "solid"),
    panel.grid.major = element_line(size = 0.5, linetype = 'solid',
                                    colour = "white"), 
    panel.grid.minor = element_line(size = 0.25, linetype = 'solid',
                                    colour = "white")
  )
```

```{r}
edx %>%
  summarize(n_users = n_distinct(userId),
            n_movies = n_distinct(movieId))
```
It is assumed that each row represents a rating given by one user to one movie, the number of unique values for the userId is 69878 and for the movieId 10677 : Both usersId and movieId which are presented as integer should be presumably treated as factors for analysis purposes. This invariably means that there are less movies provided for ratings than users that rated them . If we think in terms of a large matrix, with user on the rows and movies on the columns, the challenge would be the sparsity of the matrix. This large matrix will contain many empty cells. This would further present a problem of dimensionality.These issues would be treated in further analysis.

```{r}
# histogram of number of ratings by movieId
edx %>% 
  count(movieId) %>% 
  ggplot(aes(n)) + 
  geom_histogram( bins=30, color = "black") +
  scale_x_log10() + 
  ggtitle("Movies") +
  labs(subtitle  ="number of ratings by movieId", 
       x="movieId" , 
       y="number of ratings", 
       caption ="source data : edx set") +
  theme(panel.border = element_rect(colour="purple", fill=NA)) 
```

```{r}
# histogram of number of ratings by userId
edx %>% 
  count(userId) %>% 
  ggplot(aes(n)) + 
  geom_histogram( bins=30, color = "gold") +
  scale_x_log10() + 
  ggtitle("Users") +
  labs(subtitle ="number of ratings by UserId", 
       x="userId" , 
       y="number of ratings") +
  theme(panel.border = element_rect(colour="black", fill=NA)) 
```
Visual exploration of the number of ratings by movieId and by userId shows the following relationships : some movies get rated more than others, and some users are more active than others at rating movies. This explains the presence of movies and users effect.
```{r}
edx %>% 
  mutate(date = round_date(as_datetime(timestamp), unit = "week")) %>%
  group_by(date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth() +
  ggtitle("Timestamp, time unit : week")+
  labs(subtitle = "average ratings",
       caption = "source data : edx set")
```

```{r}
edx %>% 
  mutate(date = round_date(as_datetime(timestamp), unit = "year")) %>%
  group_by(date) %>%
  summarize(rating = mean(rating)) %>%
  ggplot(aes(date, rating)) +
  geom_point() +
  geom_smooth() +
  ggtitle("Timestamp, time unit : year")+
  labs(subtitle = "average ratings",
       caption = "source data : edx set")
```
Analyzing the trend of the average ratings versus date, shows that time has a weak effect on the average ratings as presented in the scatter plot.
###Data Preprocessing###
There is need for the processing of real-life data example includes cleansing, filtering, transformation in order to be used for the machine learning algorithm.
This section mainly focuses on data preprocessing techniques that are of particular importance when designing a Recommender system. These techniques include similarity measures (such as Euclidean distance, Cosine distance,etc) , sampling methods , and dimensionality reduction (such as PCA or SVD).
It has earlier been highlighted in the Data exploration step the problem of  sparsity when considering a large matrix with users on the rows and movies on the columns, hence the need to build an effective matrix.
##Data transformation##
Trying to build our matrix, we somehow encountered that with the huge amount of data we have, the dcast , acast functions of the reshape2 and data.table packages are very time consuming and don’t allocate vectors of size more than 2.8G. Then, we decided to go further with the Matrix packages : Matrix and Matrix.utils which contain the sparseMatrix function. The latter is less time consuming and deal more efficiently with the memory problem.
```{r}
#Edx dataset transformation:usersId and movieId should be treat as factors for some analysis purposes.
edx.copy <- edx
edx.copy$userId <- as.factor(edx.copy$userId)
edx.copy$movieId <- as.factor(edx.copy$movieId)
```

```{r}
#SparseMatrix function is used in order to get an output 0f sparse matrix of class dgcMatrix.
# To use this function, the userId & movieId are converted to numeric vectors.

edx.copy$userId <- as.numeric(edx.copy$userId)
edx.copy$movieId <- as.numeric(edx.copy$movieId)

sparse_ratings <- sparseMatrix(i = edx.copy$userId,
                         j = edx.copy$movieId ,
                         x = edx.copy$rating, 
                         dims = c(length(unique(edx.copy$userId)),
                                  length(unique(edx.copy$movieId))),  
                         dimnames = list(paste("u", 1:length(unique(edx.copy$userId)), sep = ""), 
                                        paste("m", 1:length(unique(edx.copy$movieId)), sep = "")))
```

```{r}
#Remove the copy created

rm(edx.copy)
```

```{r}
#The first 10 users
sparse_ratings[1:10,1:10]
```

```{r}
##Convert rating matrix into a recommenderlab sparse matrix
rate_Mat <- new("realRatingMatrix", data = sparse_ratings)
rate_Mat
```

##Similarity measures##
Data mining techniques are used for the modelling of different recommender systems approaches( collaborative filtering, content based, hybrid methods) are highly dependent on defining an appropriate similarity or distance measure.
To measure the similarity between users or between items, the following measures are used Minkowski Distance, Mahalanobis distance, Pearson correlation and Cosine similarity. The cosine similarity which is a measure of similarity between two non-zero vectors of an inner product space which measures the cosine of the angle between them. 
The main advantages of using this distance measure, as reported by Saranya et al (2016) includes:
1. Solves the problem of sparsity, scalability and cold start and it is more robust to noise.
2. It improves prediction accuracy and consistency
3. The Cosine similarity can still be calculated even though the matrix has many missing elements.
4. As the dimensional space becomes large, it still works well with low Computational complexity , especially for sparse vectors.

As a result of the large nature of the data, similarity on the first 50 users are calculated for visualization.
```{r}
#calculate the user similarity using the cosine similarity
similarity_users <- similarity(rate_Mat[1:50,], 
                               method = "cosine", 
                               which = "users")

```

```{r}
image(as.matrix(similarity_users), main = "similarity of Users")

```

```{r}
#Using the same approach, compute similarity between  movies.

similarity_movies <- similarity(rate_Mat[,1:50], 
                               method = "cosine", 
                               which = "items")

```

```{r}
image(as.matrix(similarity_movies), main = "similarity of Movies")
```
In the given matrices above, each row and column corresponds to a user, and each cell corresponds to the similarity between two users . The more red the cell is, the more similar two users are. Note that the diagonal is red, since it’s comparing each user with itself.
From the observation of the two similarity matrices, the following inferences are drawn; there are more similar ratings between certain users and movies than others, this can therefore be an evidence that the existence of a group of users pattern or a group of movies pattern exist.
##Dimension Reduction##
The inference from the analysis of the previous similarity matrices leads to the thought that the possibility of users and movies with similar rating patterns. However Sparsity and the curse of dimensionality remain a recurent problem, and we have to deal with many NA too. Dimensionality reduction techniques such as “pca” and “svd” can help overcome these problem by transforming the original high-dimensional space into a lower-dimensionality.
To face the RAM memory problem, we are going to use the Irlba package, which it is a fast and memory-efficient way to compute a partial SVD. The augmented implicitly restarted Lanczos bidiagonalization algorithm (IRLBA) finds a few approximate largest (or, optionally, smallest) singular values and corresponding singular vectors of a sparse or dense matrix using a method of Baglama and Reichel, which is further substantiated by Irizarry, 2018, on matrix factorization.

```{r}
set.seed(1, sample.kind = "Rounding")
Y <- irlba(sparse_ratings,tol=1e-4,verbose=TRUE,nv = 100, maxit = 1000)

```

```{r}
# plot singular values
plot(Y$d, pch=20, col = "blue", cex = 1.5, xlab='Singular Value', ylab='Magnitude', 
     main = "User-Movie Matrix")
```


```{r}
# calculate sum of squares of all singular values
all_sing_val <- sum(Y$d^2)
```


```{r}
# variability described by first 6, 12, and 20 singular values
first_six <- sum(Y$d[1:6]^2)
print(first_six/all_sing_val)
```

```{r}
first_twl <- sum(Y$d[1:12]^2)
print(first_twl/all_sing_val)
```

```{r}
first_twt <- sum(Y$d[1:20]^2)
print(first_twt/all_sing_val)
```

```{r}
perc_vec <- NULL
for (i in 1:length(Y$d)) {
  perc_vec[i] <- sum(Y$d[1:i]^2) / all_sing_val
}

plot(perc_vec, pch=20, col = "blue", cex = 1.5, xlab='Singular Value', ylab='% Sum of Squares of Singular Values', main = "k for Dimensionality Reduction")
lines(x = c(0,100), y = c(.90, .90))
```
First six singular values explain more than half of the variability of the imputed ratings matrix, with the first dozen explaining nearly 70% and the first twenty explaining more than 75%. However,the goal is to identify the first k singular values whose squares sum to at least 90% of the total of the sums of the squares of all of the singular values. A plot of a running sum of squares for the singular values shows that the 90% hurdle is achieved using somewhere between 50 and 60 singular values.

```{r}
#value of K
k = length(perc_vec[perc_vec <= .90])
k
```


```{r}
#get the decomposition of Y ; matrices U, D, and V
U_k <- Y$u[, 1:k]
dim(U_k)
```

```{r}
D_k <- Diagonal(x = Y$d[1:k])
dim(D_k)
```

```{r}
V_k <- t(Y$v)[1:k, ]
dim(V_k)
```
It is noticed that k=55 will retain 90% of variability. Therefore, the total number of numeric values required to house these component matrices is 
(69878∗55)+(55∗55)+(55∗10677)=4,433,550
(69878∗55)+(55∗55)+(55∗10677)=4,433,550. This represents an approximately 50.7% decrease in required storage relative to the original 9,000,055 entries.
Reducing the dimensionality, the RAM memory problem persists. Thats why we needed to go further with another reduction technique. We selected the relevant data using the whole rating matrix.

##Relevant Data##
It is important reiterate that some users saw more movies than others. So, instead of displaying some random users and movies, instead an intentional approach to select the most relevant users and movies is put in place, this therefore aids in the visualization of only the users who have seen many movies and the movies that have been seen by many users.To identify and select the most relevant users and movies, the following steps are adopted:
1. Determine the minimum number of movies per user.
2. Determine the minimum number of users per movie.
3. Select the users and movies matching these criteria.

```{r}
#1. Determine the minimum number of movies per user.
min_no_movies <- quantile(rowCounts(rate_Mat), 0.9)
print(min_no_movies)
```

```{r}
#2. Determine the minimum number of users per movie.
min_no_users <- quantile(colCounts(rate_Mat), 0.9)
print(min_no_users)
```

```{r}
#3. Select the users and movies matching these criteria.
rate_movies <- rate_Mat[rowCounts(rate_Mat) > min_no_movies,
                            colCounts(rate_Mat) > min_no_users]
rate_movies
```

From the analysis so far, the rating matrix obtained consist of 6978 distinct users in rows x 1068 distinct movies in columns, with 2,313,148 ratings . 
The data preprocessing phase is usually not definitive because it requires a lot of attention and subsequently, various explorations on the variables. It must be aimed at obtaining better predictive results and in this sense, the further phases of model evaluations can help us to understand which particular preprocessing approaches are actually indispensable or useful for a specific model purpose. 

```{r}
#define the RMSE function
RMSE <- function(true_ratings, predicted_ratings){
    sqrt(mean((true_ratings - predicted_ratings)^2))
  }
```


#movie effect#
```{r}
#calculate the average of all ratings of the edx dataset
mu <- mean(edx$rating)
```


```{r}
#calculate b_i on the training dataset
movie_m <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))
```

```{r}
# predicted ratings
predicted_ratings_bi <- mu + validation %>% 
  left_join(movie_m, by='movieId') %>%
  .$b_i
```

#movie + user effect#
```{r}
#calculate b_u using the training set 
user_m <- edx %>%  
  left_join(movie_m, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))
```


```{r}
#predicted ratings
predicted_ratings_bu <- validation %>% 
  left_join(movie_m, by='movieId') %>%
  left_join(user_m, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  .$pred
```

#movie + user + time effect#
```{r}
#create a copy of validation set , valid, and create the date feature which is the timestamp converted to a datetime object  and  rounded by week.
valid <- validation
valid <- valid %>%
  mutate(date = round_date(as_datetime(timestamp), unit = "week")) 

```


```{r}
#calculate time effects ( b_t) using the training set
temp_m <- edx %>%
  left_join(movie_m, by='movieId') %>%
  left_join(user_m, by='userId') %>%
  mutate(date = round_date(as_datetime(timestamp), unit = "week")) %>%
  group_by(date) %>%
  summarize(b_t = mean(rating - mu - b_i - b_u))
```

  
```{r}
#predicted ratings
predicted_ratings_bt <- valid %>% 
  left_join(movie_m, by='movieId') %>%
  left_join(user_m, by='userId') %>%
  left_join(temp_m, by='date') %>%
  mutate(pred = mu + b_i + b_u + b_t) %>%
  .$pred
```

#calculate the RMSE for movies, users and time effects#
```{r}
#calculate the RMSE for movies
rmse_model_1 <- RMSE(validation$rating,predicted_ratings_bi)  
rmse_model_1
```

```{r}
#calculate the RMSE for users
rmse_model_2 <- RMSE(validation$rating,predicted_ratings_bu)
rmse_model_2
```

```{r}
#calculate the RMSE for time effects
rmse_model_3 <- RMSE(valid$rating,predicted_ratings_bt)
rmse_model_3
```
From the movie and user effects combined, our RMSE decreased by almost 10% with respect to the only movie effect. The improvement on the time effect is not significant,(about a decrease of 0.011%). The regularization would be performed using only the movie and user effects.


```{r}
#remove valid before regularization
rm(valid)
```
#Regularization# 
```{r}
## remembering that lambda is a tuning parameter. We can use cross-validation to choose it
lambdas <- seq(0, 10, 0.25)
```
```{r}
rmses <- sapply(lambdas, function(l){
    
    mu_reg <- mean(edx$rating)
    
    b_i_reg <- edx %>% 
      group_by(movieId) %>%
      summarize(b_i_reg = sum(rating - mu_reg)/(n()+l))
    
    b_u_reg <- edx %>% 
      left_join(b_i_reg, by="movieId") %>%
      group_by(userId) %>%
      summarize(b_u_reg = sum(rating - b_i_reg - mu_reg)/(n()+l))
    
    predicted_ratings_b_i_u <- 
      validation %>% 
      left_join(b_i_reg, by = "movieId") %>%
      left_join(b_u_reg, by = "userId") %>%
      mutate(pred = mu_reg + b_i_reg + b_u_reg) %>%
      .$pred
    
    return(RMSE(validation$rating,predicted_ratings_b_i_u))
  })
```
```{r}
qplot(lambdas, rmses)  
```

#For the full model, the optimal  λ#
```{r}
#For the full model, the optimal  λ  is given as
lambda <- lambdas[which.min(rmses)]
lambda
```

```{r}
rmse_model_4 <- min(rmses)
rmse_model_4
```

#summarize all the rmse on validation set for Linear regression models#

```{r}
#summarize all the rmse on validation set for Linear regression models
rmse_results <- data.frame(methods=c("movie effect","movie + user effects","movie + user + time effects", "Regularized Movie + User Effect Model"),rmse = c(rmse_model_1, rmse_model_2,rmse_model_3, rmse_model_4))

```
```{r}
kable(rmse_results) %>%
  kable_styling(bootstrap_options = "striped" , full_width = F , position = "center") %>%
  kable_styling(bootstrap_options = "bordered", full_width = F , position ="center") %>%
  column_spec(1,bold = T ) %>%
  column_spec(2,bold =T ,color = "white" , background ="#D7261E")
```
The regularization gets down the RMSE’s value to 0.8648170.

#POPULAR , UBCF and IBCF algorithms of the recommenderlab package#
```{r}
#POPULAR algorithms of the recommenderlab package
model_pop <- Recommender(rate_movies, method = "POPULAR", 
                      param=list(normalize = "center"))
```
```{r}
#prediction example on the first 10 users
pred_pop <- predict(model_pop, rate_movies[1:10], type="ratings")
as(pred_pop, "matrix")[,1:10]
```

#Calculation of rmse for popular method#
```{r}
set.seed(1, sample.kind = "Rounding")
#Calculation of rmse for popular method
eval <- evaluationScheme(rate_movies, method="split", train=0.7, given=-5)
```

```{r}
#ratings of 30% of users are excluded for testing
model_pop <- Recommender(getData(eval, "train"), "POPULAR")

prediction_pop <- predict(model_pop, getData(eval, "known"), type="ratings")

rmse_pop <- calcPredictionAccuracy(prediction_pop, getData(eval, "unknown"))[1]
rmse_pop
```
#Estimating rmse for UBCF using Cosine similarity and selected n as 50 based on cross-validation#

```{r}
#Estimating rmse for UBCF using Cosine similarity and selected n as 50 based on cross-validation
set.seed(1, sample.kind = "Rounding")
model <- Recommender(getData(eval, "train"), method = "UBCF", 
                     param=list(normalize = "center", method="Cosine", nn=50))

prediction <- predict(model, getData(eval, "known"), type="ratings")

rmse_ubcf <- calcPredictionAccuracy(prediction, getData(eval, "unknown"))[1]
rmse_ubcf
```
#Estimating rmse for IBCF using Cosine similarity and selected n as 350 based on cross-validation#
```{r}
#Estimating rmse for IBCF using Cosine similarity and selected n as 350 based on cross-validation
set.seed(1, sample.kind = "Rounding")

model <- Recommender(getData(eval, "train"), method = "IBCF", 
                     param=list(normalize = "center", method="Cosine", k=350))

prediction <- predict(model, getData(eval, "known"), type="ratings")

rmse_ibcf <- calcPredictionAccuracy(prediction, getData(eval, "unknown"))[1]
rmse_ibcf
```

```{r}
rmse_crossvalidation <- data.frame(methods=c("Popularity-Based model","User-based Model"," Item-Based Model"),rmse = c(rmse_pop,rmse_ubcf ,rmse_ibcf))

```
```{r}
kable(rmse_crossvalidation) %>%
  kable_styling(bootstrap_options = "striped" , full_width = F , position = "center") %>%
  kable_styling(bootstrap_options = "bordered", full_width = F , position ="center") %>%
  column_spec(1,bold = T ) %>%
  column_spec(2,bold =T ,color = "white" , background ="#D7261E")
```

```{r}
plot(rmse_crossvalidation, annotate = 1, legend = "topleft")
title("ROC curve, Three Models")
```

Root mean square error (RMSE) the standard deviation of the difference between the real and predicted ratings, the higher the error, the worse the model performs.
##Matrix Factorization Method with parallel stochastic gradient descent##
```{r}
#Before to perform MF method, i clear unusued memory
invisible(gc())
```
```{r}
#create a copy of training(edx) and validation sets which retains only userId, movieId and rating features, renaming the three columns.

edx.copy <-  edx %>%
            select(-c("genres","title","timestamp"))

names(edx.copy) <- c("user", "item", "rating")


valid.copy <-  validation %>%
  select(-c("genres","title","timestamp"))

names(valid.copy) <- c("user", "item", "rating")


#as matrix
edx.copy <- as.matrix(edx.copy)
valid.copy <- as.matrix(valid.copy)

```
```{r}
#write edx.copy and valid.copy tables on disk 
write.table(edx.copy , file = "trainset.txt" , sep = " " , row.names = FALSE, col.names = FALSE)
write.table(valid.copy, file = "validset.txt" , sep = " " , row.names = FALSE, col.names = FALSE)
```
```{r}
#  data_file(): Specifies a data set from a file in the hard disk. 

set.seed(123) # This is a randomized algorithm
train_set <- data_file(system.file( "dat" ,"trainset.txt" , package = "recosystem"))
valid_set <- data_file(system.file( "dat" ,"validset.txt" , package = "recosystem"))
```
```{r}
#Next step is to build Recommender object
r = Reco()
```
```{r}
# Matrix Factorization :  tuning training set

opts = r$tune(train_set, opts = list(dim = c(10, 20, 30), lrate = c(0.1, 0.2),
                                     costp_l1 = 0, costq_l1 = 0,
                                     nthread = 1, niter = 10))
opts
```
```{r}
# Matrix Factorization : trains the recommender model

r$train(train_set, opts = c(opts$min, nthread = 1, niter = 20))
```
##Increasing model performance##
Based on the different RMSE’s values, Linear regression model with Regularized movie + user effect and Matrix factorization with stochastic gradient, best predict ratings on the validation dataset.

```{r}
#create a copy of training(edx) and validation sets which retain only userId, movieId and rating features. Renaming the three columns.

edx.copy <-  edx %>%
            select(-c("genres","title","timestamp"))

names(edx.copy) <- c("user", "item", "rating")


valid.copy <-  validation %>%
  select(-c("genres","title","timestamp"))

names(valid.copy) <- c("user", "item", "rating")

```
```{r}
#as matrix
edx.copy <- as.matrix(edx.copy)
valid.copy <- as.matrix(valid.copy)
```
```{r}
#write edx.copy and valid.copy tables on disk 
write.table(edx.copy , file = "trainset.txt" , sep = " " , row.names = FALSE, col.names = FALSE)
write.table(valid.copy, file = "validset.txt" , sep = " " , row.names = FALSE, col.names = FALSE)
```
```{r}
#data_file(): Specifies a data set from a file in the hard disk. 

set.seed(123) # This is a randomized algorithm
train_set <- data_file(system.file( "dat" ,"trainset.txt" , package = "recosystem"))
valid_set <- data_file(system.file( "dat" ,"validset.txt" , package = "recosystem"))
```
```{r}
#Next step is to build Recommender object
r = Reco()
```
```{r}
#Optimizing/tuning the recommender model
opts <- r$tune(train_set , opts = list(dim = c(1:20), lrate = c(0.05),
                                            nthread = 4 , costp_l1=0, 
                                            costq_l1 = 0,
                                            niter = 50, nfold = 10,
                                            verbose = FALSE))
```
```{r}
#trains the recommender model
r$train(train_set, opts = c(opts$min , nthread = 4, niter = 100,verbose=FALSE))

```
```{r}
#Making prediction on validation set and calculating RMSE:
pred_file = tempfile()

r$predict(valid_set, out_file(pred_file))  
```

```{r}
#Matrix Factorization : show first 10 predicted values
print(scan(pred_file, n = 10))
```

```{r}
#valid_set
scores_real <- read.table("validset.txt", header = FALSE, sep = " ")$V3
scores_pred <- scan(pred_file)
```
```{r}
# remove edx.copy and valid.copy objects
rm(edx.copy, valid.copy)
```
```{r}
rmse_mf_opt <- RMSE(scores_real,scores_pred)

rmse_mf_opt
```

```{r}
iter.line <- 15
tr_rmse.line <- mat.facto_rmse$tr_rmse[which(mat.facto_rmse$iter==15)]


mat.facto_rmse %>% 
  ggplot(aes(x=iter, y = tr_rmse))+
  geom_point(size= 5 , shape = 19 ) + 
  geom_smooth(aes(x= iter, y = tr_rmse)) +
  geom_segment(x=0,xend=iter.line ,y=tr_rmse.line,yend=tr_rmse.line, color="red", lty=2)+
  geom_segment(x=iter.line, xend=iter.line, y=0, yend=tr_rmse.line, color="red", lty=2) +
  annotate(geom="label",x = iter.line,y = 0.8350,color=2,     
           label=paste("x=",round(iter.line,0),"\ny=",round(tr_rmse.line ,4)))+
  labs(title="RMSE for different number of latent factors" ,
       caption = "based on the output of r$train(train_set, opts = c(opts$min, nthread = 4, niter = 100), \n show just first 30 iterations)"
  ) +
  ylab("RMSE") +
  xlab("Latent factors")
```

The focus is to optimize the performance of matrix factorization with stochastic gradient using 10 fold cross validation ( nfolds = 10). This consisted to understand the behavior of the rmse value for the Matrix Factorization recommender engine when modifying values of number of latent factors (dim), gradient descend step rate (lrate), penalty parameters to avoid overfitting (cost) and number of threads for parallel computing (nthread). The figure above shows the number of latent factors vs. cross-validation RMSE . It is observed that the training model just needed 15 latent factors to reach a rmse value lower than 0.8. To sum up, we observed that even with these optimal criteria, the RMSE value for the Matrix factorization method is still below 0.8.(see value of rmse_mf_opt)

###Conclusion###
This MovieLens project has examined the potential best recommender system algorithm to predict movie ratings for the 10M version of the Movielens data. Using the provided training set (edx) and validation set, we successively trained different linear regression models and some recommender engines. The model evaluation performance through the RMSE ( root mean squared error) showed that the Linear regression model with regularized effects on users and movies, and the Matrix Factorization with Stochastic gradient descent are the two appropriate recommender systems to predict ratings on the validation set. Using 10 fold cross-validation to increase the performance of the Matrix Factorization method , in line with the understanding the behavior of the rmse value with changing optimal criteria( dim, nthread, lrate, lim), it is natable to present an rmse value that is less than 0.8.
###Recommendations###
The research strongly reccommend the following for further investigations using other models, such as essemble which was not possible due to hardware issues.  


This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
